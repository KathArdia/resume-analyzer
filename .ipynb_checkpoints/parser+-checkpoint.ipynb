{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Что делает код:*** <bhr>\n",
        "\n",
        "***Собирает вакансии:*** согласно позиции которую вы задаете (н-р data analyst)\n",
        "\n",
        "Парсит вакансии по заданной специальности за последние **30** дней.\n",
        "Удаляет дубликаты по названию и работодателю.<bhr>\n",
        "\n",
        "***Анализирует технологии:***\n",
        "\n",
        "Сравнивает требования вакансий со списком технологий.\n",
        "Считает упоминания каждой технологии.\n",
        "Сортирует технологии по убыванию частоты упоминаний. ***(top 10)***"
      ],
      "metadata": {
        "id": "FynCQ55zpFEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import trange\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Список технологий для анализа\n",
        "technologies = [\n",
        "    'Python', 'SQL', 'Java', 'Scala', 'Bash', 'Git', 'Docker', 'Kubernetes',\n",
        "    'Apache Airflow', 'Luigi', 'ETL', 'PostgreSQL', 'MySQL', 'MongoDB', 'Cassandra',\n",
        "    'Redis', 'DynamoDB', 'Amazon Redshift', 'Snowflake', 'Google BigQuery',\n",
        "    'Teradata', 'Apache Hadoop', 'Apache Spark', 'Apache Kafka', 'Hive', 'Flink',\n",
        "    'Hadoop', 'Spark', 'Kafka', 'Hive', 'Flink', 'Dask', 'Delta Lake', 'Presto',\n",
        "    'Trino', 'ElasticSearch', 'AWS', 'S3', 'Redshift', 'Glue', 'Lambda',\n",
        "    'Google Cloud Platform', 'BigQuery', 'DataFlow', 'Pub/Sub', 'Microsoft Azure',\n",
        "    'Data Factory', 'Synapse Analytics', 'Blob Storage', 'Tableau', 'Power BI',\n",
        "    'Looker', 'QlikView', 'Grafana', 'Superset', 'Domo', 'Excel', 'Power Query',\n",
        "    'Power Pivot', 'Google Analytics', 'Google Sheets', 'A/B тестирование','Selenium','JUnit','pytest','TestNG','Cypress','Appium',\n",
        "    'Postman','SoapUI','LoadRunner','Gatling','TensorFlow','PyTorch','Scikit-learn','Keras','Hugging', 'Face','OpenAI','APIs','ChatGPT','GPT',\n",
        "    'MLflow','H2O.ai','LightGBM','XGBoost','Tableau','Power BI','Looker','Grafana','Superse','QlikView','Qlik','Domo','Matplotlib','Seaborn',\n",
        "    'Plotly','Docker','Kubernetes','Jenkins','GitLab','CI/CD','Ansible','Terraform','Puppet','Chef','Helm','OpenShift','AWS','Azure','Cloud','Amazon',\n",
        "    'IBM Cloud','Oracle Cloud','Alibaba Cloud','DigitalOcean','Heroku','Vercel','Linode','MySQL','DynamoDB','Oracle Database','MariaDB','Neo4j','HTML',\n",
        "    'CSS','Node.js','PHP','React','Angular','Vue.js','SASS/SCSS','jQuery','Django','Flask','Fast','JavaScript','C#','TypeScript','Swift','Kotlin','Go'\n",
        "    ,'Golang','Rust','Scala','R','Dart','Perl',' Objective-C','Visual Basic','Shell (Bash)','Groovy'\n",
        "]\n",
        "\n",
        "# Функция для получения страницы вакансий\n",
        "def getPages(page=0, vacancy=None, date_from=None, date_to=None):\n",
        "    \"\"\"Функция для получения страницы вакансий.\"\"\"\n",
        "    url = \"https://api.hh.ru/vacancies\"\n",
        "    params = {\n",
        "        'text': vacancy,\n",
        "        'per_page': 100,\n",
        "        'page': page,\n",
        "        'date_from': date_from,\n",
        "        'date_to': date_to\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "        return response.json()\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Ошибка запроса: {e}\")\n",
        "        return None\n",
        "\n",
        "# Функция для обработки вакансий\n",
        "def process_vacancies(data):\n",
        "    \"\"\"Обрабатывает вакансии и возвращает DataFrame.\"\"\"\n",
        "    return pd.DataFrame([\n",
        "        {\n",
        "            'name': item.get('name'),\n",
        "            'area': item.get('area', {}).get('name'),\n",
        "            'employer': item.get('employer', {}).get('name'),\n",
        "            'published_at': item.get('published_at'),\n",
        "            'requirement': item.get('snippet', {}).get('requirement', ''),\n",
        "            'url': item.get('alternate_url')\n",
        "        }\n",
        "        for item in data\n",
        "    ])\n",
        "\n",
        "# Функция для анализа технологий\n",
        "def analyze_technologies(requirements_list, technologies):\n",
        "    \"\"\"Анализ технологий в требованиях вакансий.\"\"\"\n",
        "    text_data = ' '.join(requirements_list).lower()\n",
        "    text_data = re.sub(r'[^\\w\\s]', '', text_data)  # Убираем пунктуацию\n",
        "    words = text_data.split()\n",
        "    word_count = Counter(words)\n",
        "\n",
        "    # Считаем частоту технологий\n",
        "    tech_count = {tech.lower(): word_count.get(tech.lower(), 0) for tech in technologies}\n",
        "    # Сортируем технологии по убыванию упоминаний\n",
        "    sorted_tech = sorted(tech_count.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_tech\n",
        "\n",
        "# Основной парсинг\n",
        "def parse_vacancies(vacancy, technologies, days=30):\n",
        "    \"\"\"Парсинг вакансий за последний месяц.\"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "    start_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
        "\n",
        "    print(f\"Парсинг вакансий '{vacancy}' с {start_date} по {end_date}...\")\n",
        "\n",
        "    for page in trange(0, 20):  # Ограничение: 20 страниц\n",
        "        data = getPages(page=page, vacancy=vacancy, date_from=start_date, date_to=end_date)\n",
        "        if data is None or not data.get('items'):\n",
        "            break\n",
        "\n",
        "        df_temp = process_vacancies(data['items'])\n",
        "        df = pd.concat([df, df_temp], ignore_index=True)\n",
        "\n",
        "    # Удаляем дубликаты вакансий\n",
        "    df = df.drop_duplicates(subset=['name', 'employer'])\n",
        "\n",
        "    # Подсчёт вакансий\n",
        "    total_vacancies = len(df)\n",
        "    print(f\"Всего уникальных вакансий: {total_vacancies}\")\n",
        "\n",
        "    # Анализ технологий\n",
        "    if 'requirement' in df.columns:\n",
        "        requirements_list = df['requirement'].dropna().tolist()\n",
        "        tech_summary = analyze_technologies(requirements_list, technologies)\n",
        "    else:\n",
        "        tech_summary = []\n",
        "\n",
        "    # Вывод анализа\n",
        "    print(\"\\nТоп-10 технологий по убыванию упоминаний:\")\n",
        "    for tech, count in tech_summary[:10]:  # Ограничиваем вывод до топ-10\n",
        "        print(f\"{tech}: {count} упоминаний\")\n",
        "\n",
        "    return df, tech_summary[:10]  # Возвращаем только топ-10\n",
        "\n",
        "\n",
        "# Запуск\n",
        "if __name__ == \"__main__\":\n",
        "    vacancy_name = input(\"Введите название вакансии: \")\n",
        "    df, tech_summary = parse_vacancies(vacancy_name, technologies, days=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRvA691qfvLe",
        "outputId": "bc7c7073-057f-4dc0-f928-fb94b90386e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Введите название вакансии: system analyst\n",
            "Парсинг вакансий 'system analyst' с 2024-11-24 по 2024-12-24...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:39<00:00,  1.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего уникальных вакансий: 1716\n",
            "\n",
            "Топ-10 технологий по убыванию упоминаний:\n",
            "sql: 162 упоминаний\n",
            "postgresql: 25 упоминаний\n",
            "python: 24 упоминаний\n",
            "excel: 19 упоминаний\n",
            "java: 13 упоминаний\n",
            "kafka: 13 упоминаний\n",
            "postman: 12 упоминаний\n",
            "docker: 8 упоминаний\n",
            "etl: 6 упоминаний\n",
            "mysql: 5 упоминаний\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}